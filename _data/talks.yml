talks:
  - id: "in-gim"
    title: "Guest Speaker: In Gim"
    date: "Dec 12, 2025"
    abstract: "As LLMs become the core of modern AI applications, inference efficiency has become critical, not just for speed but also for sustainability. An old lesson of systems design is that efficiency arises from understanding the workload. Yet today’s LLM serving systems are largely application agnostic. They are optimized for generic text completion, while real applications now perform far richer tasks such as invoking tools, retrieving data, executing code, and coordinating with other agents. It raises a question: How should we rethink LLM serving, not from the system’s perspective, but from the application’s? In this talk, I will explore that question and show how an application-centered approach leads to serving systems that are more programmable, flexible, and application aware."
    speaker_bio: "In Gim is a fourth-year Ph.D. student at Yale University, advised by Prof. Lin Zhong. His research focuses on systems for machine learning, specifically on programmable systems for AI. His first-author works have been recognized by venues like SOSP, MLSys, MobiSys, HotOS, EMNLP, and AAAI."

  - id: "lequn-chen"
    title: "Guest Speaker: Lequn Chen"
    date: "Nov 21, 2025"
    abstract: "As Large Language Models (LLMs) scale and Mixture-of-Experts (MoE) architectures gain prominence, inter-node communication becomes increasingly critical. Current LLM systems rely heavily on collective communication patterns through APIs like torch.distributed and NCCL, following a Single Program Multiple Data (SPMD) model that imposes unnecessary constraints on peer-to-peer data movement. This talk revisits RDMA-based peer-to-peer communication patterns for modern LLM workloads. While peer-to-peer communication is well-established, it has been largely overlooked in contemporary LLM systems. We examine RDMA primitives and present our communication library API design through three critical use cases: (1) KvCache transfer for disaggregated inference, (2) weight transfer between training and inference nodes during RL rollouts, and (3) MoE dispatch-combine all-to-all kernels."
    speaker_bio: "Lequn graduated PhD from UW inn 2024. Lequn is currently a Research Engineer at Perplexity AI, building a better answer engine."
  
  - id: "lakshya-agrawal"
    title: "Guest Speaker: Lakshya Agrawal"
    date: "Nov 7, 2025"
    abstract: "Large language models (LLMs) are increasingly adapted to downstream tasks via reinforcement learning (RL) methods like Group Relative Policy Optimization (GRPO), which often require thousands of rollouts to learn new tasks. We argue that the interpretable nature of language often provides a much richer learning medium for LLMs, compared to policy gradients derived from sparse, scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt optimizer that thoroughly incorporates natural language re-flection to learn high-level rules from trial and error. Given any AI system containing one or more LLM prompts, GEPA samples trajectories (e.g., reasoning, tool calls, and tool outputs) and reflects on them in natural language to diagnose problems, propose and test prompt updates, and combine complementary lessons from the Pareto frontier of its own attempts. As a result of GEPA's design, it can often turn even just a few rollouts into a large quality gain. Across four tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer, MIPROv2, by over 10% (e.g., +10% accuracy on AIME-2025)."
    speaker_bio: "Lakshya A Agrawal is a second-year PhD student in the Sky Lab at UC Berkeley, advised by Prof. Matei Zaharia and Prof. Dan Klein. His research tackles critical challenges in AI, focusing on sample-efficient agentic optimization and AI system reliability. He recently developed GEPA: a reflective prompt optimizer that can outperform reinforcement learning in sample-efficiency, and mmGRPO: an RL algorithm for tuning complex AI systems. His work on reliability includes contributions to MAST, the first taxonomy and study of multi-agent system failures, and the langProBe benchmark. Prior to Berkeley, Lakshya was an AI4Code research fellow at Microsoft Research, where he worked to improve the reliability of LLM-generated code through integration of static-analysis tools in LLM-code generation pipelines, and created multilspy, a leading Python client for integrating coding agents with IDE tools."
    
  - id: "jonathan-balkind"
    title: "Rethinking Prediction for System Tuning and Architectural Modeling"
    date: "Oct 17, 2025"
    abstract: "In this talk, I will cover two recent papers from our lab, both adopting prediction in unconventional ways. Time permitting, I will also talk a little about our plans to enable hardware-enforced, privacy-preserving prediction of tenants' applications by cloud providers. To better facilitate application performance programming we propose a software optimization strategy enabled by a novel low-latency Prediction System Service (PSS). Rather than relying on nuanced domain-specific knowledge or slapdash heuristics, a system service for prediction encourages programmers to spend their time uncovering new levers for optimization rather than worrying about the details of their control. The core idea is to write optimizations that improve performance in specific cases, or under specific tunings, and leave the decision of how and when exactly to apply those optimizations to the system to learn through feedback-directed learning. Such a prediction service can be implemented in any number of ways, including as a shared library that can be easily reused by software written in different programming languages, and opens the door to both new software optimization patterns and hardware design possibilities. Modern applications exhibit memory access patterns with complex spatial and temporal relationships. Traditional architectural simulators utilized to evaluate these applications are highly sequential in nature, particularly for stateful components like caches. We present an innovative approach to cache simulation by reframing the problem from a deep learning perspective. We exploit the fact that memory access traces in any part of a processor design can be represented as two-dimensional heatmaps. Our key insight is that the behaviour of a cache acts as a filter on these heatmap images which can be learned as a function using deep learning techniques. Leveraging this observation, we introduce CacheBox, a framework that employs a Generative Adversarial Network (GAN) to learn and replicate the filtering behaviour of caches using memory access heatmaps. We demonstrate that CacheBox effectively generalises across multiple state-of-the-art benchmarks, various cache configurations, different cache hierarchy levels, and even alternative microarchitectural structures with high accuracy."
    speaker_bio: "Jonathan Balkind is an Assistant Professor in the Department of Computer Science at the University of California, Santa Barbara. His research interests lie at the intersection of Computer Architecture, Programming Languages, and Operating Systems. Jonathan completed his PhD and MA degrees at Princeton University and his MSci degree at the University of Glasgow. Jonathan was an Open Hardware Trailblazer Fellow and recipient of the NSF CAREER Award. Since 2021, he has served as a Director of the FOSSi Foundation."
    
  - id: "yicheng-liu"
    title: "SOSP practice talk: Yicheng Liu (UCLA)"
    date: "Oct 10, 2025"
    abstract: "Modern software inevitably encounters periods of resource overload, during which it must still sustain high servicelevel objective (SLO) attainment while minimizing request loss. However, achieving this balance is challenging due to subtle and unpredictable internal resource contention among concurrently executing requests. Traditional overload control mechanisms, which rely on global signals, such as queuing delays, fail to handle application resource overload effectively because they cannot accurately predict which requests will monopolize critical resources. In this paper, we propose Atropos, an overload control framework that proactively cancels the culprit request that cause severe resource contention rather than the victim requests that are blocked by it. Atropos continuously monitors the resource usage of executing requests, identifies the requests contributing most significantly to resource overload, and selectively cancels them. We integrate Atropos into six large-scale applications and evaluate it against 16 real-world overload scenarios. Our results show that Atropos maintains the performance goals while achieving minimal request drop, significantly outperforming state-of-the-art solutions."
    speaker_bio: "Yicheng is a second-year Ph.D. student at UCLA, co-advised by Sam Kumar and Harry Xu. Yicheng was an undergraduate student at Shanghai Jiao Tong University (SJTU). When Yicheng was an undergraduate student at SJTU, Yicheng was an intern at Institution of Parallel And Distributed System (IPADS), advised by Jinyu Gu. In the 2024 Summer, Yicheng was an intern in University of Washington, System Group, advised by Baris Kaciksi and mentored by Yigong Hu. In the 2023 Summer, Yicheng visited and took part in the research in University of Michigan, OrderLab, advised by Ryan Huang."
    
  - id: "nishil-talati"
    title: "Guest Speaker: Nishil Talati (UIUC)"
    date: "Oct 3, 2025"
    abstract: "Diffusion-based text-to-image generation models trade latency for quality: small models are fast but generate lower quality images, while large models produce better images but are slow. In this talk, I will present our recent work MoDM, a novel image caching-based serving system for diffusion models that dynamically balances latency and quality through a mixture of diffusion models. The key enabler of this idea is the concept of image cache that allows a consistently high image generation quality at a high performance. This design enables adaptive serving by dynamicallybalancing latency and image quality: using smaller models for cache-hit requests to reduce latency while reserving larger models for cache-miss requests to maintain quality. Small model image quality is preserved using retrieved cached images. MoDM is agnostic to any model or model family, showing effectiveness across Flux, Stable Diffusion, and SANA. Towards the end of this talk, I will present important lessons I learned while doing this research."
    speaker_bio: "Nishil Talati is an Assistant Research Scientist in the CSE department at the University of Michigan and an incoming Assistant Professor in the CS department at University of Illinois, Urbana-Champaign (UIUC). His research focuses on computer architecture and systems software design to enhance the efficiency of generative AI and data analytics applications. Nishil's work has been featured in leading venues including ISCA, MICRO, HPCA, ASPLOS and VLDB, and has been recognized with several awards including Research Faculty Recognition Award, IEEE computing's top 30 early career professional award, HPCA best paper award and honorable best paper mentions at DATE 2023, IISWC 2023, and recognition as a 2023 ProQuest Distinguished Dissertation Award Finalist."

  - id: "aashaka-shah"
    title: "Guest Speaker: Aashaka Shah (Microsoft)"
    date: "Sep 12, 2025"
    abstract: "AI applications increasingly run on distributed and fast-evolving heterogeneous hardware to maximize performance, but general-purpose libraries lag in supporting these features. Performance-minded programmers often build custom communication stacks that are fast but error-prone and non-portable. In this talk, we will introduce the Microsoft Collective Communication Library++ (MSCCL++), a collective communication framework that provides a design methodology for developing high-performance, portable communication kernels. MSCCL++ has (1) a low-level, performance-preserving primitive interface that exposes minimal hardware abstractions while hiding the complexities of synchronization and consistency, (2) a higher-level DSL for application developers to implement workload-specific communication algorithms, and (3) a library of efficient algorithms implementing the standard collective API, enabling adoption by users with minimal expertise. Compared to state-of-the-art baselines, MSCCL++ achieves geomean speedups of 1.7x (up to 5.4x) for collective communication and 1.2x (up to 1.4x) for AI inference workloads. MSCCL++ is in production of multiple AI services provided by Microsoft Azure and has also been adopted by RCCL and SGLang. It is open source and available at https://github.com/microsoft/mscclpp. Our two years of experience with MSCCL++ suggest that its abstractions are robust, enabling support for new hardware features, such as multimem, within weeks of development."
    speaker_bio: "Aashaka Shah is a researcher in the Research in Software Engineering (RiSE) group at Microsoft Research. She is interested in building high-performance ML systems, in particular, by optimizing GPU interconnect network utilization and efficient memory management. Her works have been published in top-tier systems, architecture, and ML conferences (NSDI, ISCA, ATC, ICLR). She graduated with her PhD from UT Austin, where she worked on problems at the intersection of systems and ML. Roshan Dathathri is a researcher in the Systems Research Group at Microsoft Research. He received his PhD from the University of Texas at Austin, where he was advised by Dr. Keshav Pingali. His research interests are broadly in the field of programming languages and systems, with an emphasis on optimizing compilers and runtime systems for distributed and heterogeneous architectures. His current focus is on building efficient systems for AI. His past work included building systems for distributed, heterogeneous graph processing and privacy-preserving neural network inferencing. His work has been published in PLDI, ASPLOS, VLDB, IPDPS, PPoPP, and other conferences."

  - id: "xingyang-li"
    title: "Guest Speaker: Xingyang Li (MIT)"
    date: "Sep 5, 2025"
    abstract: "Diffusion models are capable of generating photo-realistic images and videos, showing a promising future for AIGC. However inference speed, training speed and memory efficiency hinder their deployment in real world as well as their long-context ability. In this talk, I will present our recent works, RadialAttention and SVDQuant. Radial Attention identifies the Spatiotemporal Energy Decay in video diffusion models: post-softmax attention scores diminish as spatial and temporal token distance increases. Guided by this motivation, we translates this energy decay into a unified and static mask with exponentially decaying compute density, which is sub-quadratic and allows longer video generation through efficient LoRA-based fine-tuning. Radial Attention accelerates default-length video generation with quality maintained for state-of-the-art video diffusion models and allows up to 4 times longer video generation with high quality. SVDQuant targets at 4-bit diffusion models, which is challenging due to high sensitivity in both weights and activations. The method facilitates conventional smoothing techniques by using a high-precision, low-rank branch to take in the weight outliers with Singular Value Decomposition (SVD), while a low-bit quantized branch handles the residuals. Moreover, its co-designed inference engine Nunchaku fuses the low-rank branch kernels into the low-bit branch to eliminate redundant memory access. SVDQuant enables off-the-shelf W4A4 diffusion models with high fidelity and up to a 3.1 times speedup on RTX 5090 GPUs."
    speaker_bio: "Xingyang Li is a senior undergraduate at ACM Honors Class, SJTU. He is currently a student intern at MIT HAN Lab, advised by Professor Song Han. His research focuses on developing efficient algorithms and systems for deep learning, with applications in the realm of computer vision. Before starting the internship at MIT, he conducted research in algorithm-hardware co-design for vision applications like 3D Gaussian Splatting and Video Transformers, and his works were published in top-tier EDA conferences including DAC and ICCAD. He is also seeking a Ph.D. position starting in 2026 Fall."

  - id: "esha-choukse"
    title: "Guest Speaker: Esha Choukse (Azure)"
    date: "Aug 22, 2025"
    abstract: "This talk explores two fronts of scaling AI: reducing inference latency and boosting throughput on emerging model types and usecases, and addressing the power and cooling demands of hyperscale data centers. I'll highlight platform-level optimizations that improve efficiency and responsiveness, and show how infrastructure design choices—spanning power delivery to efficient cooling—are becoming inseparable from AI system performance and sustainability."
    speaker_bio: "Esha Choukse is a Principal Researcher in the Azure Research- Systems team. Esha is currently leading the efficient AI research project, working on cross-stack projects to optimize the AI platform (scheduling/routing), hardware, and datacenter infrastructure for emerging GenAI workloads in cloud, working toward the goal of datacenter efficiency and sustainability."

  - id: "animesh-dangwal"
    title: "Guest Speaker: Animesh Dangwal (UCSB)"
    date: "Aug 15, 2025"
    abstract: "Edge computing distributes cloud functionality to task specific, resource-constrained and low-cost devices operating at data collection points, for low latency, low power and cost effective compute. This coordination requires redesigning cloud paradigms to either communicate or compute over the edge. Rather than adapting cloud technologies for edge constraints, what if we reconfigure the edge environment to enable seamless adoption of cloud research with minimal modifications to existing algorithms and runtimes? In this work, we define this transformation by modelling an edge rack analogous to server racks in the cloud to construct a high performance edge cluster. This allows us to explore the impact of cloud scheduling and runtime paradigms to the edge using metrics such as temperature, voltage fluctuations and maintenance cost such as cooling. In this talk, I present my work on exploring scheduling principles for such giant edge clusters, using UCSB's (and unofficially the world's) largest Raspberry Pi cluster, and reveal how metric fluctuations are magnified for edge workloads."
    speaker_bio: "Animesh Dangwal is a 5th year PhD student in the Computer Science department at UC Santa Barbara, working with Professor Chandra Krintz and Professor Rich Wolski. His research interests are in edge, serverless computing and distributed systems. His recent work has been in bridging the gap between the edge and cloud by developing flexible, and sustainable deployments at the edge for diverse workloads and hardware."

  - id: "yutong-bai"
    title: "Guest Speaker: Yutong Bai (UC Berkeley)"
    date: "Aug 1, 2025"
    abstract: "We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human."
    speaker_bio: "Yutong is currently a Postdoc Researcher at UC Berkeley (BAIR), advised by Prof. Alexei (Alyosha) Efros, Prof. Jitendra Malik and Prof. Trevor Darrell. Prior to that, she obtained CS PhD degree at Johns Hopkins University advised by Prof. Alan Yuille. She used to intern at Meta AI (FAIR Labs) and Google Brain, and was selected as 2023 Apple Scholar and MIT EECS Rising Star. Her work was norminated for CVPR 2022 Best Paper Award."
    homepage: "https://yutongbai.com/"

  - id: "yeonju-ro"
    title: "Guest Speaker: Yeonju Ro (UT Austin)"
    date: "July 18, 2025"
    abstract: "LLM inference is becoming increasingly challenging as models grow in architectural complexity and are expected to handle ever-longer input contexts. Architectures like Mixture of Experts (MoE) introduce conditional computation, leading to irregular execution patterns and inefficiencies in memory usage and batching. Meanwhile, context windows often span hundreds of thousands of tokens—driven by bursty inputs and prolonged sessions—straining memory and compute resources, particularly in Transformer layers. To address these challenges, we explore the use of late binding techniques for adaptive serving. In Read-ME, we defer batching and scheduling decisions until after routing paths are computed. Unlike conventional layerwise routers, our proposed decoupled Read-ME router supports precomputation of expert assignments, enabling informed scheduling. This allows for expert-aware batching that aligns with routing patterns, significantly boosting MoE serving throughput. Next, we explore architectural late binding to address the compute and memory overhead of long-context inference. In DSLA-Serve, we progressively convert Transformer layers into Dual-State Linear Attention (DSLA) layers—a new linear attention architecture. This conversion is guided by a sensitivity-based layer ordering and adapts to system load at inference time, replacing more layers as needed to balance efficiency and accuracy."
    speaker_bio: "Yeonju Ro is a Ph.D. student at the University of Texas at Austin, co-advised by Professors Aditya Akella and Atlas Wang. Her research focuses on systems for machine learning, algorithm–system co-design, and applying machine learning to systems problems. She has worked at Microsoft Azure, Meta, HP Labs, and Samsung Research. She is a recipient of the 2024 IBM PhD Fellowship."
    homepage: "https://sites.google.com/view/hey-yeonju"

  - id: "xiangpeng-hao-liquidcache"
    title: "Guest Speaker: Xiangpeng Hao (UW-Madison)"
    date: "July 11, 2025"
    abstract: "We present LiquidCache, a novel pushdown-based disaggregated caching system that evaluates filters on cache servers before transmitting data to compute nodes, which addresses our key observation that data decoding, not filter evaluation, is the primary bottleneck by transcoding Parquet data into a lightweight, cache-exclusive \"Liquid\" format that is co-designed with filter evaluation semantics to enable selective decoding, late filter materialization, and encoding-aware filter evaluation for low decoding costs and high compression ratios, allowing easy adoption without breaking ecosystem compatibility and demonstrating through integration with Apache DataFusion and evaluation with ClickBench and TPC-H that it reduces cache CPU time by up to 10× without increasing memory footprint and cuts network traffic by two orders of magnitude compared to non-pushdown systems."
    speaker_bio: "Xiangpeng Hao is a fifth year PhD student at UW-Madison adviced by Andrea Arpaci-Dusseau and Remzi Arpaci-Dusseau. His research focuses on building large scale analytical data systems. Notably, his PhD is supported by industry funding he independently raised through the LiquidCache project."

  - id: "yuxuan-jiang-traincheck"
    title: "Guest Speaker: Yuxuan Jiang (UMich)"
    date: "June 27, 2025"
    abstract: "Training deep learning (DL) models is a complex process, making it prone to silent errors that are challenging to detect and diagnose. This paper presents TrainCheck, a framework that takes a proactive checking approach to address silent training errors. TrainCheck automatically infers invariants tailored for DL training. It uses these invariants to proactively detect silent errors during the training process while providing debugging help. To evaluate TrainCheck, we reproduce 20 real-world silent training errors with diverse root causes. TRAINCHECK successfully detects 18 errors within a single training iteration. It also uncovers 6 unknown bugs in popular training libraries that lead to silent errors."
    speaker_bio: "Yuxuan Jiang is a second-year Ph.D. student in Computer Science and Engineering at the University of Michigan, advised by Prof. Ryan Huang. His research focuses on building tools to improve the reliability of cloud-scale and machine learning systems, with an emphasis on detecting silent failures and automating quality checks. He is the creator of TrainCheck, a runtime monitoring framework that proactively detects training bugs by inferring and checking invariants during deep learning training. Yuxuan is currently interning at Microsoft Research, where he is working on AIOps, and will be based in Seattle for the summer."
    homepage: "https://essoz.github.io/"

  - id: "zhiyuan-zeng-evaltree"
    title: "Guest Speaker: Zhiyuan Zeng (UWNLP)"
    date: "June 20, 2025"
    abstract: "An ideal model evaluation should achieve two goals: identifying where the model fails and providing actionable improvement guidance. However, current model evaluations commonly fail to achieve these goals by reducing model performance to a single aggregate metric, thereby obscuring the model's heterogeneous performance across diverse capabilities tested within a benchmark. In this talk, I will introduce how we advance the two goals by formulating the research problem of generating a weakness profile, a set of weaknesses expressed in natural language, given a language model's performance on every individual instance in a benchmark. I will introduce a new weakness profiling method, EvalTree. EvalTree automatically constructs a tree for any benchmark that hierarchically organizes and interprets the capabilities tested within the benchmark; it then extracts nodes where the model performs poorly to generate a weakness profile. Experiments show that EvalTree profiles model weaknesses more precisely and comprehensively than existing weakness profiling methods, and that synthetic data generation guided by EvalTree-identified weaknesses effectively improves model performance. I will also talk about how EvalTree exposes flaws in Chatbot Arena's human-voter-based evaluation practice. To facilitate future work, we provide an interface that allows practitioners to interactively explore the capability trees built by EvalTree."
    speaker_bio: "Zhiyuan Zeng is a first-year Ph.D. student in the Paul G. Allen School of Computer Science & Engineering at the University of Washington, advised by Hannaneh Hajishirzi and Pang Wei Koh. Previously, he received his bachelor's degree from the Department of Computer Science and Technology at Tsinghua University in China, where he worked with Danqi Chen at Princeton University and Zhiyuan Liu at Tsinghua University. Zhiyuan is a recipient of the 2022 SenseTime Scholarship, the 2022 China National Scholarship for undergraduate students, and a Gold Medal in the National Olympiad in Informatics (NOI) 2019."
    homepage: "https://zhiyuan-zeng.github.io/"
